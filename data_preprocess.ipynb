{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "listing_info_fn = 'listing_info.csv'\n",
    "test_fn = 'test.csv'\n",
    "train_fn = 'train.csv'\n",
    "user_behavior_logs_fn = 'user_behavior_logs.csv'\n",
    "user_info_fn = 'user_info.csv'\n",
    "user_repay_logs_fn  = 'user_repay_logs.csv'\n",
    "user_taglist_fn = 'user_taglist.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_listing_info_fn = 'preprocess_listing_info.csv'\n",
    "preprocess_test_fn = 'preprocess_test.csv'\n",
    "preprocess_train_fn = 'preprocess_train.csv'\n",
    "preprocess_user_behavior_logs_fn = 'preprocess_user_behavior_logs.csv'\n",
    "preprocess_user_info_fn = 'preprocess_user_info.csv'\n",
    "preprocess_user_repay_logs_fn  = 'preprocess_user_repay_logs.csv'\n",
    "preprocess_user_taglist_fn = 'preprocess_user_taglist.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_train_data_listing_info_fn = 'preprocess_train_data_listing_info.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### listing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_info_data = pd.read_csv(data_path+listing_info_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_info_data.loc[listing_info_data['user_id'] == 712075].sort_values('auditing_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_info_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_info_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(data_path+train_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due_interval\n",
    "train_data['due_interval'] = (pd.to_datetime(train_data['due_date']) - pd.to_datetime(train_data['auditing_date'])).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2 = train_data.loc[train_data['repay_date']==r'\\N']\n",
    "train_data_1 = train_data.loc[train_data['repay_date']!=r'\\N']\n",
    "train_data_1.loc[:,'repay_interval'] = (pd.to_datetime(train_data_1['repay_date']) - pd.to_datetime(train_data_1['auditing_date'])).dt.days\n",
    "train_data_2.loc[:,'repay_interval'] = 60000\n",
    "train_data = train_data_1.append(train_data_2)\n",
    "train_data = train_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['repay_due_interval'] = train_data['repay_interval'] - train_data['due_interval']\n",
    "train_data.loc[train_data['repay_due_interval'] > 0, 'repay_due_interval'] = 1\n",
    "train_data.drop(['repay_interval'], axis=1, inplace=True)\n",
    "train_data['repay_amt'] = train_data['due_amt']\n",
    "train_data.loc[train_data['repay_due_interval'] > 0, 'repay_amt'] = 0\n",
    "\n",
    "# train_data.to_csv (\"train_preprocess.csv\", index=False, encoding = \"utf-8\")\n",
    "# df = pd.read_csv(\"./train_preprocess.csv\", encoding = \"utf-8\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(data_path+preprocess_train_fn, index=False, encoding = \"utf-8\")\n",
    "df = pd.read_csv(data_path+preprocess_train_fn, encoding = \"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess user_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = pd.read_csv(data_path+user_info_fn, header=0, index_col=False, names=['user_id', 'reg_mon', 'gender', 'age', 'cell_province', 'id_province', 'id_city', 'insertdate'])\n",
    "gender_mapping = {label: idx for idx,label in enumerate(set(user_info['gender']))}\n",
    "user_info['gender'] = user_info['gender'].map(gender_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cell_province_mapping = {label: idx for idx,label in enumerate(sorted(set(user_info['cell_province']), reverse=True))}\n",
    "# print('\\ncell_province_mapping:', cell_province_mapping)\n",
    "user_info['cell_province'] = user_info['cell_province'].map(cell_province_mapping)\n",
    "\n",
    "id_province_mapping = {label: idx for idx,label in enumerate(sorted(set(user_info['id_province']), reverse=True))}\n",
    "# print('\\nid_province_mapping:', id_province_mapping)\n",
    "user_info['id_province'] = user_info['id_province'].map(id_province_mapping)\n",
    "\n",
    "id_city_mapping = {label: idx for idx,label in enumerate(sorted(set(user_info['id_city']), reverse=True))}\n",
    "# print('\\nid_city_mapping:', id_city_mapping)\n",
    "user_info['id_city'] = user_info['id_city'].map(id_city_mapping)\n",
    "\n",
    "user_info['insert_ts'] = user_info['insertdate'].apply(lambda date: pd.to_datetime(date).timestamp())\n",
    "\n",
    "user_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = pd.read_csv(data_path+preprocess_user_info_fn)\n",
    "user_info.drop(['Unnamed: 0'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "user_info = pd.concat([user_info, pd.DataFrame(columns=['insertdata_first','insertdata_last', 'insertdata_times'])], sort=True)\n",
    "user_info_copy = user_info.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "handled_index_list = []\n",
    "count = 0\n",
    "for idx, row in user_info.iterrows():\n",
    "    count += 1\n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "    try:\n",
    "        temp_user = user_info_copy.loc[user_info_copy['user_id'] == row['user_id']]\n",
    "        temp_user_insterdata_times = len(temp_user)\n",
    "        if temp_user_insterdata_times == 0:\n",
    "            print('error')\n",
    "            break\n",
    "        if temp_user_insterdata_times == 1:        \n",
    "            user_info_copy.loc[idx, 'insertdata_first'] = temp_user['insert_ts'].values[0]\n",
    "            user_info_copy.loc[idx, 'insertdata_last'] = temp_user['insert_ts'].values[0]\n",
    "            user_info_copy.loc[idx, 'insertdata_times'] = 1\n",
    "            continue\n",
    "        if idx in handled_index_list:\n",
    "            continue\n",
    "        else:\n",
    "            handled_index_list.append(idx)\n",
    "        temp_user_ts = temp_user['insert_ts']\n",
    "        temp_user_ts_max = temp_user_ts.max()\n",
    "        temp_user_ts_min = temp_user_ts.min()\n",
    "        temp_user_ts_dict = {v:k for k, v in temp_user_ts.to_dict().items()}\n",
    "        temp_user_ts_max_idx = temp_user_ts_dict[temp_user_ts_max]\n",
    "        temp_user_index_list = temp_user.index.to_list()\n",
    "        temp_user_index_list.remove(temp_user_ts_max_idx)\n",
    "        user_info_copy.drop(index=temp_user_index_list, axis=0, inplace=True)\n",
    "        user_info_copy.loc[temp_user_ts_max_idx, 'insertdata_first'] = temp_user_ts_min\n",
    "        user_info_copy.loc[temp_user_ts_max_idx, 'insertdata_last'] = temp_user_ts_max\n",
    "        user_info_copy.loc[temp_user_ts_max_idx, 'insertdata_times'] = temp_user_insterdata_times\n",
    "    except:\n",
    "        print(row['user_id'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_info_copy.loc[user_info_copy['user_id'] == 173388.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_670044_ts = user_info.loc[user_info['user_id'] == 670044]['insert_ts']\n",
    "user_ts_670044_dict = {v:k for k, v in user_ts_670044_ts.to_dict().items()}\n",
    "print('ts:', user_ts_670044_ts.min(), user_ts_670044_ts.max())\n",
    "print('index:', user_ts_670044_dict[user_ts_670044_ts.min()], user_ts_670044_dict[user_ts_670044_ts.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_670044 = user_info.loc[user_info['user_id'] == 670044]\n",
    "handled_index_list = []\n",
    "print(user_ts_670044.index.to_list() in [[59861, 61420, 61588]])\n",
    "handled_index_list.append(user_ts_670044.index.to_list())\n",
    "handled_index_list\n",
    "user_ts_670044_index_list = user_ts_670044.index.to_list()\n",
    "user_ts_670044_index_list.remove(user_ts_670044_dict[user_ts_670044_ts.max()])\n",
    "print(user_ts_670044_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_670044_dict[user_ts_670044_ts.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_ts_670044.index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_670044_dict[user_ts_670044_ts.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([1,2,3].remove(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info.to_csv(data_path+preprocess_user_info_fn, index=False, encoding='utf-8')\n",
    "df = pd.read_csv(data_path+preprocess_user_info_fn, encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess user_repay_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_repay_logs_data = pd.read_csv(data_path+user_repay_logs_fn)\n",
    "user_repay_logs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_repay_logs_data.loc[user_repay_logs_data['user_id'] == 777528].sort_values(['listing_id', 'due_date']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_repay_logs_data.loc[user_repay_logs_data['repay_date'] == r'2200-01-01'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_repay_logs_data['repay_due_interval'] = (pd.to_datetime(user_repay_logs_data['repay_date']) - pd.to_datetime(user_repay_logs_data['due_date'])).dt.days\n",
    "user_repay_logs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_repay_logs_data.to_csv(data_path+preprocess_user_repay_logs_fn)\n",
    "df = pd.read_csv(data_path+preprocess_user_repay_logs_fn, encoding = \"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess user_taglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_taglist_data = pd.read_csv(data_path+user_taglist_fn)\n",
    "user_taglist_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_taglist_new = user_taglist_data.drop(['taglist'], axis=1).join(user_taglist_data['taglist'].str.split('|', expand=True).stack().reset_index(level=1, drop=True).rename('tag'))\n",
    "user_taglist_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_taglist_new.to_csv(data_path+preprocess_user_taglist_fn, index=False, encoding = \"utf-8\")\n",
    "del user_taglist_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) listing_info & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(data_path+preprocess_train_fn)\n",
    "listing_info_data = pd.read_csv(data_path+listing_info_fn, header=0, index_col=False, names=['user_id', 'listing_id', 'auditing_date', 'term', 'rate', 'principal'])\n",
    "train_listing_info_data = pd.merge(train_data, listing_info_data, on=['user_id', 'listing_id', 'auditing_date'])\n",
    "user_info_data = pd.read_csv(data_path+preprocess_user_info_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_listing_info_data.shape)\n",
    "train_listing_info_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_listing_info_data['auditing_ts'] = train_listing_info_data['auditing_date'].apply(lambda date: pd.to_datetime(date).timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_listing_info_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_listing_info_data['due_ts'] = train_listing_info_data['due_date'].apply(lambda date: pd.to_datetime(date).timestamp())\n",
    "train_listing_info_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_listing_info_data.to_csv(data_path+preprocess_train_data_listing_info_fn, index=False, encoding='utf-8')\n",
    "del train_listing_info_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) user_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_listing_info_data = pd.read_csv(data_path+preprocess_train_data_listing_info_fn, encoding='utf-8')\n",
    "user_info_data = pd.read_csv(data_path+preprocess_user_info_fn)\n",
    "user_info_data.drop(['Unnamed: 0'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "new_train_listing_info_data = None\n",
    "for index,row in train_listing_info_data.iterrows():\n",
    "    count += 1\n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "#         break\n",
    "    temp_trainlist_rdf = row.to_frame().T.rename({0:index}, axis='index')\n",
    "#     print('temp_trainlist_rdf:', temp_trainlist_rdf)\n",
    "    valid_ts = row['auditing_ts']\n",
    "    uid = row['user_id']\n",
    "    matchinfo = user_info_data.loc[user_info_data['user_id']==uid]\n",
    "    if len(matchinfo) > 1:\n",
    "        matchinfo = matchinfo.sort_values('insert_ts', ascending=False)\n",
    "        for i,r in matchinfo.iterrows():\n",
    "            if r['insert_ts'] < valid_ts:\n",
    "#                 print('temp_trainlist_rdf:', temp_trainlist_rdf)\n",
    "                temp_user_rdf = r.to_frame().T.rename({i:index}, axis='index')\n",
    "                temp_trainlist_rdf = pd.merge(temp_trainlist_rdf, temp_user_rdf, left_on=['user_id'], right_on=['user_id'], how='outer', sort=True).rename({0:index}, axis='index')\n",
    "#                 print('temp_user_rdf:', temp_user_rdf)\n",
    "#                 print('temp_trainlist_rdf', temp_trainlist_rdf)\n",
    "#                 print('temp_trainlist_rdf:', temp_trainlist_rdf)\n",
    "                if new_train_listing_info_data is None:\n",
    "                    new_train_listing_info_data = temp_trainlist_rdf\n",
    "                else:\n",
    "                    new_train_listing_info_data = pd.concat([new_train_listing_info_data, temp_trainlist_rdf], sort=True)\n",
    "        \n",
    "        print('new_train_listing_info_data:',new_train_listing_info_data)\n",
    "        if new_train_listing_info_data is not None:\n",
    "            if 'age_x' in new_train_listing_info_data.columns:\n",
    "                break\n",
    "#                 print('===', new_train_listing_info_data)\n",
    "#                 train_listing_info_data = pd.merge(train_listing_info_data, rdf, on=['user_id'], how='outer')\n",
    "#         print(train_listing_info_data.loc[train_listing_info_data['user_id'] == 795130])\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_listing_info_data.loc[train_listing_info_data['user_id'] == 957]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_listing_info_data.loc[957,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_info_data.loc[user_info_data['user_id'] == 595855]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_train_listing_info_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_listing_info_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_listing_info_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_listing_info_data.loc[train_listing_info_data['user_id'] == 795130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_preprocess.csv')\n",
    "listing_info = pd.read_csv('listing_info.csv', index_col=False, names=['user_id', 'listing_id', 'auditing_date', 'term', 'rate', 'principal'])\n",
    "user_info = pd.read_csv('user_info_preprocess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_listing_info = pd.merge(train_data, listing_info, on=['user_id', 'listing_id', 'auditing_date'])\n",
    "# train_data_listing_info.drop(['due_date'], axis=1, inplace=True)\n",
    "train_data_listing_info['auditing_ts'] = train_data_listing_info['auditing_date'].apply(lambda date: pd.to_datetime(date).timestamp())\n",
    "# train_data_listing_info['due_ts'] = train_data_listing_info['due_date'].apply(lambda date: pd.to_datetime(date).timestamp())\n",
    "# train_data_listing_info['repay_ts'] = train_data_listing_info['repay_date'].apply(lambda date: pd.to_datetime(date).timestamp())\n",
    "train_data_listing_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
